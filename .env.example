# ================
# Server Settings
# ================
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=info
DEBUG=false

# ================
# Authentication
# ================
# Comma-separated list of API keys for authentication
API_KEYS=your-api-key-here

# ================
# Local LLM Providers
# ================

# Ollama
OLLAMA_BASE_URL=http://localhost:11434

# vLLM
VLLM_BASE_URL=http://localhost:8000
VLLM_MODEL=TheBloke/Mistral-7B-Instruct-v0.1-GGUF

# LM Studio
LMSTUDIO_BASE_URL=http://localhost:1234

# ================
# Cloud LLM Providers
# ================

# OpenAI
OPENAI_API_KEY=your-openai-api-key
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_MODEL=claude-3-opus-20240229

# Google Gemini
GEMINI_API_KEY=your-gemini-api-key
GEMINI_MODEL=gemini-1.5-pro

# Perplexity AI
PERPLEXITY_API_KEY=your-perplexity-api-key

# ================
# Chat Terminal
# ================
CHAT_HISTORY_SIZE=1000
DEFAULT_PROVIDER=anthropic
DEFAULT_MODEL=claude-3-opus-20240229
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000

# ================
# Caching
# ================
ENABLE_CACHE=true
CACHE_TTL=3600  # 1 hour

# ================
# Rate Limiting
# ================
RATE_LIMIT=100  # requests per minute
RATE_LIMIT_WINDOW=60  # seconds
